{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import glob2 as glob\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "import logging\n",
    "import cv2\n",
    "import squarify\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_csv = pd.read_csv('../Annotations/processedAnnotations_no_corrupted_videos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_csv = proc_csv.set_index('palavra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_csv['len_palavra'] = proc_csv.index.map(lambda x:len(x))\n",
    "proc_csv = proc_csv[proc_csv['len_palavra'] > 0]\n",
    "proc_csv = proc_csv.drop(['video_url', 'configuracao_mao', 'filename', 'len_palavra'], axis=1)\n",
    "proc_csv['letra'] = proc_csv.index.map(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_csv = proc_csv.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_csv.to_csv('../Annotations/annotationsForVis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTIONS = 30\n",
    "TIMEOUT = 5\n",
    "labels = np.unique(csv['CM'])\n",
    "urls_CM = np.unique(csv['configuracao_mao'])\n",
    "urls_videos = csv['video_url']\n",
    "filenames = csv['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url_images(url, index, folder):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(folder + labels[index] + '.jpg', 'wb').write(r.content)\n",
    "    \n",
    "def load_url_videos(url, index, folder):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(folder + filenames[index], 'wb').write(r.content)\n",
    "    \n",
    "def getAllFiles (pathToFiles):\n",
    "    files = []\n",
    "    files = glob.glob(pathToFiles + '/*/*.mp4', recursive=True)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=CONNECTIONS) as executor:\n",
    "    future_to_url = {executor.submit(load_url_videos, url, index, \"Videos/\") : url for index, url in enumerate(urls_videos)}\n",
    "    time1 = time.time()\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (url, exc))\n",
    "        finally:\n",
    "            csv.loc[csv['video_url'] == url, 'downloaded'] = 'ok'\n",
    "            print(str(len(out)),end=\"\\r\")\n",
    "            \n",
    "    time2 = time.time()\n",
    "\n",
    "print(f'Took {time2-time1:.2f} s')\n",
    "print(pd.Series(out).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating inner directories so as to organize videos by alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/fabiana/Desktop/projeto-final-src/Crawler/Videos\"\n",
    "pfPath = \"/home/fabiana/Desktop/projeto-final-src/Crawler\"\n",
    "files = getAllFiles(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    filename = file.rsplit('/', 1)[1]\n",
    "    letter = filename[0]\n",
    "    if (not os.path.isdir(path + '/' + letter)):\n",
    "        os.mkdir(path + '/' + letter)\n",
    "    os.rename(file, path + '/' + letter + '/' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating log to keep track of corrupted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "    format='%(asctime)s [%(levelname)s] - %(message)s',\n",
    "    filename=\"/home/fabiana/Desktop/projeto-final-src/Crawler/corruptedFiles.log\",\n",
    "   filemode='w')\n",
    "\n",
    "for file in files:\n",
    "    cap = cv2.VideoCapture(file)\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if (length < 1):\n",
    "        logging.error('There are no frames in ' + file)\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
